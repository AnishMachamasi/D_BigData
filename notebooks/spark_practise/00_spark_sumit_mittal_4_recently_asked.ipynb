{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00660e70-7ae7-495c-a1f3-d8ea08cdda61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e81a2b4-e67c-4748-a13f-9c99f5972c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Sumit_Mittal_4_recently_asked_questions\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb48d326-4711-4168-a2e7-2057fb46a7d1",
   "metadata": {},
   "source": [
    "## Question 1: There is a parquet file stored in datalake, write a pyspark code to read this file and create a dataframe. Then write a code to remove the duplicate records. Write back the dataframe back to the data lake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ccac6d-cdc7-4edb-a91a-84e9876aff50",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca66c8b-dd1d-4631-87da-ef5f5ca07689",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"path/to/your/parquet/file\"\n",
    "\n",
    "destination = \"path/to/your/output/results\"\n",
    "\n",
    "df = spark.read.parquet(source)\n",
    "\n",
    "df.show()\n",
    "\n",
    "## remove the duplicates\n",
    "result_df_no_duplicates =  df.dropDuplicates()\n",
    "\n",
    "result_df_no_duplicates.show()\n",
    "\n",
    "## write back the result\n",
    "result_df_no_duplicates.write.parquet(destination, mode = \"overwrite\")\n",
    "\n",
    "## Stopping the SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04b19e2-179c-41b4-820f-d551a652e1e8",
   "metadata": {},
   "source": [
    "## Question 2: \n",
    "\n",
    "#### Input\n",
    "\n",
    "col1      col2      col3\n",
    "\n",
    "a          aa        1\n",
    "\n",
    "a          aa        2\n",
    "\n",
    "b          bb        5\n",
    "\n",
    "b          bb        3\n",
    "\n",
    "b          bb        4\n",
    "\n",
    "#### Output\n",
    "col1      col2      col3\n",
    "\n",
    "a          aa        [1, 2]\n",
    "\n",
    "b          bb       [5,3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f66737c8-cd27-4206-ab6f-95c0c4e89287",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input Data\n",
    "data = [\n",
    "    (\"a\", \"aa\", 1),\n",
    "    (\"a\", \"aa\", 2),\n",
    "    (\"b\", \"bb\", 5),\n",
    "    (\"b\", \"bb\", 3),\n",
    "    (\"b\", \"bb\", 4),\n",
    "]\n",
    "\n",
    "## schema\n",
    "schema = [\"col1\", \"col2\", \"col3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "161d1711-708e-416e-9a94-e3c65e157b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataframe\n",
    "df = spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1948cf6f-3c0a-40c7-a5fc-439d068b5e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|col1|col2|col3|\n",
      "+----+----+----+\n",
      "|   a|  aa|   1|\n",
      "|   a|  aa|   2|\n",
      "|   b|  bb|   5|\n",
      "|   b|  bb|   3|\n",
      "|   b|  bb|   4|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979cd6f-8c7e-4f27-aede-bdf0794d1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f28bc85-fe5c-4c69-998a-b3cf685d41a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupBy([\"col1\", \"col2\"]).agg(collect_list(\"col3\").alias(\"col3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1ea7c21-445c-419a-9f5b-7100a681d7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+\n",
      "|col1|col2|     col3|\n",
      "+----+----+---------+\n",
      "|   a|  aa|   [1, 2]|\n",
      "|   b|  bb|[5, 3, 4]|\n",
      "+----+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fbc6ad1-d2d7-4a65-8a5f-217b585807f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69d755b6-e1ec-4ecf-b0c8-0d9760533308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.createOrReplaceTempView(\"MyTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b1c738c-f80d-4c08-87e7-9f31d8afd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = spark.sql(\"Select * from MyTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f5008e3-1789-4694-bfc9-47b0a2938a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+\n",
      "|col1|col2|     col3|\n",
      "+----+----+---------+\n",
      "|   a|  aa|   [1, 2]|\n",
      "|   b|  bb|[5, 3, 4]|\n",
      "+----+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca692c0-d154-4cd1-8c6a-a13be25d4ba1",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Read the JSON file below:\n",
    "\n",
    "{\n",
    "\"dept_id\": 101, \n",
    "\"e_id\": [10101, 10102, 10103]\n",
    "}\n",
    "\n",
    "{\n",
    "\"dept_id\": 102, \n",
    "\"e_id\": [10201, 10202]\n",
    "}\n",
    "\n",
    "Output:\n",
    "\n",
    "dept_id     e_id\n",
    "\n",
    "101         10101\n",
    "\n",
    "101         10102\n",
    "\n",
    "101         10103\n",
    "\n",
    "102         10201\n",
    "\n",
    "102         10202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "053d1507-0560-4c4d-9f18-cb87cb5da0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "json1 = { \"dept_id\": 101, \"e_id\": [10101, 10102, 10103] }\n",
    "json2 = { \"dept_id\": 102, \"e_id\": [10201, 10202] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05be9e50-6381-4ba2-bb97-400a16169b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2565d003-6361-4713-aadf-9f4b3016af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    Row(dept_id = json1[\"dept_id\"], e_id = json1[\"e_id\"]),\n",
    "    Row(dept_id = json2[\"dept_id\"], e_id = json2[\"e_id\"]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "811f6f09-4e17-484f-b321-3ddd85d1a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea10957e-4763-4d89-9da5-0dacb4e85040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|dept_id|                e_id|\n",
      "+-------+--------------------+\n",
      "|    101|[10101, 10102, 10...|\n",
      "|    102|      [10201, 10202]|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd2a6dc8-fddb-45e0-8190-ee2a7bc64d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_df = df.withColumn(\"e2_id\", explode(\"e_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01f7cd15-085c-4e15-9570-1682469b2f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----+\n",
      "|dept_id|                e_id|e2_id|\n",
      "+-------+--------------------+-----+\n",
      "|    101|[10101, 10102, 10...|10101|\n",
      "|    101|[10101, 10102, 10...|10102|\n",
      "|    101|[10101, 10102, 10...|10103|\n",
      "|    102|      [10201, 10202]|10201|\n",
      "|    102|      [10201, 10202]|10202|\n",
      "+-------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flattened_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab711f1-c4d6-4147-b4e3-913fbc0aae26",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "data = [( \"2023-01-01\", \"AAPL\", 150.00), (\"2023-01-02\", \"AAPL\", 155.00),\n",
    "(\"2023-01-01\", \"GOOG\", 2500.00), (\"2023-01-02\", \"GOOG\", 2550.00),\n",
    "(\"2023-01-01\", \"MSFT\", 300.00), (\"2023-01-02\", \"MSFT\", 310.00)]\n",
    "\n",
    "1. Create Dataframe in pyspark\n",
    "\n",
    "2. Find average stock value on daily basis for each stock\n",
    "\n",
    "3. Find the max avg stock value for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "972bf17d-434b-41a1-bb49-327353f309fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [( \"2023-01-01\", \"AAPL\", 150.00), (\"2023-01-02\", \"AAPL\", 155.00),\n",
    "(\"2023-01-01\", \"GOOG\", 2500.00), (\"2023-01-02\", \"GOOG\", 2550.00),\n",
    "(\"2023-01-01\", \"MSFT\", 300.00), (\"2023-01-02\", \"MSFT\", 310.00)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5706f480-434f-4d6d-aa7d-2f717f697b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data, schema = [\"date\", \"symbol\", \"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c19d354e-cce5-4c96-b6f4-8bf2e1878a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+\n",
      "|      date|symbol| value|\n",
      "+----------+------+------+\n",
      "|2023-01-01|  AAPL| 150.0|\n",
      "|2023-01-02|  AAPL| 155.0|\n",
      "|2023-01-01|  GOOG|2500.0|\n",
      "|2023-01-02|  GOOG|2550.0|\n",
      "|2023-01-01|  MSFT| 300.0|\n",
      "|2023-01-02|  MSFT| 310.0|\n",
      "+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2211502a-bb34-4553-ab8c-4bf95d6ddff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_avg_df = df.groupBy([\"date\", \"symbol\"]).agg(avg(\"value\").alias(\"avg_value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96d927bc-2ba0-4872-8e8a-a1f642de41cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------+\n",
      "|      date|symbol|avg_value|\n",
      "+----------+------+---------+\n",
      "|2023-01-01|  AAPL|    150.0|\n",
      "|2023-01-02|  AAPL|    155.0|\n",
      "|2023-01-01|  GOOG|   2500.0|\n",
      "|2023-01-02|  GOOG|   2550.0|\n",
      "|2023-01-01|  MSFT|    300.0|\n",
      "|2023-01-02|  MSFT|    310.0|\n",
      "+----------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "daily_avg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c7ea767-1922-49c0-ae95-89fc6356c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_avg_df = daily_avg_df.groupBy(\"symbol\").agg(max(\"avg_value\").alias(\"max_avg_value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ae21876-47ad-4e37-baaa-97b2eb09cca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|symbol|max_avg_value|\n",
      "+------+-------------+\n",
      "|  AAPL|        155.0|\n",
      "|  GOOG|       2550.0|\n",
      "|  MSFT|        310.0|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_avg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "70f045dc-1c0e-46c0-be67-95fd6988a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"date\", to_date(df.date, \"yyyy-mm-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6716785-2901-41b4-b136-e1b2d241608f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+\n",
      "|      date|symbol| value|\n",
      "+----------+------+------+\n",
      "|2023-01-01|  AAPL| 150.0|\n",
      "|2023-01-02|  AAPL| 155.0|\n",
      "|2023-01-01|  GOOG|2500.0|\n",
      "|2023-01-02|  GOOG|2550.0|\n",
      "|2023-01-01|  MSFT| 300.0|\n",
      "|2023-01-02|  MSFT| 310.0|\n",
      "+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c219456f-fdb8-445c-b546-9642f2f7a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"day\", day(df.date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84179671-dfdf-42ad-bfe5-64a6f967194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+---+\n",
      "|      date|symbol| value|day|\n",
      "+----------+------+------+---+\n",
      "|2023-01-01|  AAPL| 150.0|  1|\n",
      "|2023-01-02|  AAPL| 155.0|  2|\n",
      "|2023-01-01|  GOOG|2500.0|  1|\n",
      "|2023-01-02|  GOOG|2550.0|  2|\n",
      "|2023-01-01|  MSFT| 300.0|  1|\n",
      "|2023-01-02|  MSFT| 310.0|  2|\n",
      "+----------+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7cfa31b1-59a5-4672-9d59-8b136aa1f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_avg_df = df.groupBy([\"day\", \"symbol\"]).agg(avg(\"value\").alias(\"avg_value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1a70677-d3f2-40e4-a8ac-d0aed7119bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+\n",
      "|day|symbol|avg_value|\n",
      "+---+------+---------+\n",
      "|  1|  AAPL|    150.0|\n",
      "|  2|  AAPL|    155.0|\n",
      "|  1|  GOOG|   2500.0|\n",
      "|  2|  GOOG|   2550.0|\n",
      "|  1|  MSFT|    300.0|\n",
      "|  2|  MSFT|    310.0|\n",
      "+---+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "daily_avg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16382f53-89c6-4694-a634-d801dc1d2f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
